<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3.org/TR/html4/loose.dtd">
<html lang="en">
<head>
<title>Source code</title>
<link rel="stylesheet" type="text/css" href="../../../../../stylesheet.css" title="Style">
</head>
<body>
<div class="sourceContainer">
<pre><span class="sourceLineNo">001</span>/*<a name="line.1"></a>
<span class="sourceLineNo">002</span> * Copyright (c) 2015-2020, Oracle and/or its affiliates. All rights reserved.<a name="line.2"></a>
<span class="sourceLineNo">003</span> *<a name="line.3"></a>
<span class="sourceLineNo">004</span> * Licensed under the Apache License, Version 2.0 (the "License");<a name="line.4"></a>
<span class="sourceLineNo">005</span> * you may not use this file except in compliance with the License.<a name="line.5"></a>
<span class="sourceLineNo">006</span> * You may obtain a copy of the License at<a name="line.6"></a>
<span class="sourceLineNo">007</span> *<a name="line.7"></a>
<span class="sourceLineNo">008</span> *     http://www.apache.org/licenses/LICENSE-2.0<a name="line.8"></a>
<span class="sourceLineNo">009</span> *<a name="line.9"></a>
<span class="sourceLineNo">010</span> * Unless required by applicable law or agreed to in writing, software<a name="line.10"></a>
<span class="sourceLineNo">011</span> * distributed under the License is distributed on an "AS IS" BASIS,<a name="line.11"></a>
<span class="sourceLineNo">012</span> * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express implied.<a name="line.12"></a>
<span class="sourceLineNo">013</span> * See the License for the specific language governing permissions and<a name="line.13"></a>
<span class="sourceLineNo">014</span> * limitations under the License.<a name="line.14"></a>
<span class="sourceLineNo">015</span> */<a name="line.15"></a>
<span class="sourceLineNo">016</span><a name="line.16"></a>
<span class="sourceLineNo">017</span>package org.tribuo.regression.slm;<a name="line.17"></a>
<span class="sourceLineNo">018</span><a name="line.18"></a>
<span class="sourceLineNo">019</span>import com.oracle.labs.mlrg.olcut.config.Config;<a name="line.19"></a>
<span class="sourceLineNo">020</span>import com.oracle.labs.mlrg.olcut.config.PropertyException;<a name="line.20"></a>
<span class="sourceLineNo">021</span>import com.oracle.labs.mlrg.olcut.provenance.Provenance;<a name="line.21"></a>
<span class="sourceLineNo">022</span>import org.tribuo.Dataset;<a name="line.22"></a>
<span class="sourceLineNo">023</span>import org.tribuo.Example;<a name="line.23"></a>
<span class="sourceLineNo">024</span>import org.tribuo.ImmutableFeatureMap;<a name="line.24"></a>
<span class="sourceLineNo">025</span>import org.tribuo.ImmutableOutputInfo;<a name="line.25"></a>
<span class="sourceLineNo">026</span>import org.tribuo.SparseModel;<a name="line.26"></a>
<span class="sourceLineNo">027</span>import org.tribuo.SparseTrainer;<a name="line.27"></a>
<span class="sourceLineNo">028</span>import org.tribuo.Trainer;<a name="line.28"></a>
<span class="sourceLineNo">029</span>import org.tribuo.math.la.DenseVector;<a name="line.29"></a>
<span class="sourceLineNo">030</span>import org.tribuo.math.la.SGDVector;<a name="line.30"></a>
<span class="sourceLineNo">031</span>import org.tribuo.math.la.SparseVector;<a name="line.31"></a>
<span class="sourceLineNo">032</span>import org.tribuo.math.la.VectorTuple;<a name="line.32"></a>
<span class="sourceLineNo">033</span>import org.tribuo.provenance.ModelProvenance;<a name="line.33"></a>
<span class="sourceLineNo">034</span>import org.tribuo.provenance.TrainerProvenance;<a name="line.34"></a>
<span class="sourceLineNo">035</span>import org.tribuo.provenance.impl.TrainerProvenanceImpl;<a name="line.35"></a>
<span class="sourceLineNo">036</span>import org.tribuo.regression.Regressor;<a name="line.36"></a>
<span class="sourceLineNo">037</span>import org.tribuo.regression.Regressor.DimensionTuple;<a name="line.37"></a>
<span class="sourceLineNo">038</span>import org.tribuo.util.Util;<a name="line.38"></a>
<span class="sourceLineNo">039</span><a name="line.39"></a>
<span class="sourceLineNo">040</span>import java.time.OffsetDateTime;<a name="line.40"></a>
<span class="sourceLineNo">041</span>import java.util.Arrays;<a name="line.41"></a>
<span class="sourceLineNo">042</span>import java.util.Map;<a name="line.42"></a>
<span class="sourceLineNo">043</span>import java.util.SplittableRandom;<a name="line.43"></a>
<span class="sourceLineNo">044</span>import java.util.logging.Level;<a name="line.44"></a>
<span class="sourceLineNo">045</span>import java.util.logging.Logger;<a name="line.45"></a>
<span class="sourceLineNo">046</span><a name="line.46"></a>
<span class="sourceLineNo">047</span>import static org.tribuo.math.la.VectorTuple.DELTA;<a name="line.47"></a>
<span class="sourceLineNo">048</span><a name="line.48"></a>
<span class="sourceLineNo">049</span>/**<a name="line.49"></a>
<span class="sourceLineNo">050</span> * An ElasticNet trainer that uses co-ordinate descent. Modelled after scikit-learn's sparse matrix implementation.<a name="line.50"></a>
<span class="sourceLineNo">051</span> * Each output dimension is trained independently.<a name="line.51"></a>
<span class="sourceLineNo">052</span> * &lt;p&gt;<a name="line.52"></a>
<span class="sourceLineNo">053</span> * See:<a name="line.53"></a>
<span class="sourceLineNo">054</span> * &lt;pre&gt;<a name="line.54"></a>
<span class="sourceLineNo">055</span> * Friedman J, Hastie T, Tibshirani R.<a name="line.55"></a>
<span class="sourceLineNo">056</span> * "Regularization Paths for Generalized Linear Models via Coordinate Descent"<a name="line.56"></a>
<span class="sourceLineNo">057</span> * Journal of Statistical Software, 2010<a name="line.57"></a>
<span class="sourceLineNo">058</span> * &lt;/pre&gt;<a name="line.58"></a>
<span class="sourceLineNo">059</span> */<a name="line.59"></a>
<span class="sourceLineNo">060</span>public class ElasticNetCDTrainer implements SparseTrainer&lt;Regressor&gt; {<a name="line.60"></a>
<span class="sourceLineNo">061</span><a name="line.61"></a>
<span class="sourceLineNo">062</span>    private static final Logger logger = Logger.getLogger(ElasticNetCDTrainer.class.getName());<a name="line.62"></a>
<span class="sourceLineNo">063</span><a name="line.63"></a>
<span class="sourceLineNo">064</span>    @Config(mandatory = true,description="Overall regularisation penalty.")<a name="line.64"></a>
<span class="sourceLineNo">065</span>    private double alpha;<a name="line.65"></a>
<span class="sourceLineNo">066</span><a name="line.66"></a>
<span class="sourceLineNo">067</span>    @Config(mandatory = true,description="Ratio of l1 to l2 parameters.")<a name="line.67"></a>
<span class="sourceLineNo">068</span>    private double l1Ratio;<a name="line.68"></a>
<span class="sourceLineNo">069</span><a name="line.69"></a>
<span class="sourceLineNo">070</span>    @Config(description="Tolerance on the error.")<a name="line.70"></a>
<span class="sourceLineNo">071</span>    private double tolerance = 1e-4;<a name="line.71"></a>
<span class="sourceLineNo">072</span><a name="line.72"></a>
<span class="sourceLineNo">073</span>    @Config(description="Maximium number of iterations to run.")<a name="line.73"></a>
<span class="sourceLineNo">074</span>    private int maxIterations = 500;<a name="line.74"></a>
<span class="sourceLineNo">075</span><a name="line.75"></a>
<span class="sourceLineNo">076</span>    @Config(description="Randomises the order in which the features are probed.")<a name="line.76"></a>
<span class="sourceLineNo">077</span>    private boolean randomise = false;<a name="line.77"></a>
<span class="sourceLineNo">078</span><a name="line.78"></a>
<span class="sourceLineNo">079</span>    @Config(description="The seed for the RNG.")<a name="line.79"></a>
<span class="sourceLineNo">080</span>    private long seed = Trainer.DEFAULT_SEED;<a name="line.80"></a>
<span class="sourceLineNo">081</span><a name="line.81"></a>
<span class="sourceLineNo">082</span>    private SplittableRandom rng;<a name="line.82"></a>
<span class="sourceLineNo">083</span><a name="line.83"></a>
<span class="sourceLineNo">084</span>    private int trainInvocationCounter;<a name="line.84"></a>
<span class="sourceLineNo">085</span><a name="line.85"></a>
<span class="sourceLineNo">086</span>    /**<a name="line.86"></a>
<span class="sourceLineNo">087</span>     * For olcut.<a name="line.87"></a>
<span class="sourceLineNo">088</span>     */<a name="line.88"></a>
<span class="sourceLineNo">089</span>    private ElasticNetCDTrainer() { }<a name="line.89"></a>
<span class="sourceLineNo">090</span><a name="line.90"></a>
<span class="sourceLineNo">091</span>    public ElasticNetCDTrainer(double alpha, double l1Ratio) {<a name="line.91"></a>
<span class="sourceLineNo">092</span>        this(alpha,l1Ratio,1e-4,500,false,Trainer.DEFAULT_SEED);<a name="line.92"></a>
<span class="sourceLineNo">093</span>    }<a name="line.93"></a>
<span class="sourceLineNo">094</span><a name="line.94"></a>
<span class="sourceLineNo">095</span>    public ElasticNetCDTrainer(double alpha, double l1Ratio, long seed) {<a name="line.95"></a>
<span class="sourceLineNo">096</span>        this(alpha,l1Ratio,1e-4,500,true,seed);<a name="line.96"></a>
<span class="sourceLineNo">097</span>    }<a name="line.97"></a>
<span class="sourceLineNo">098</span><a name="line.98"></a>
<span class="sourceLineNo">099</span>    public ElasticNetCDTrainer(double alpha, double l1Ratio, double tolerance, int maxIterations, boolean randomise, long seed) {<a name="line.99"></a>
<span class="sourceLineNo">100</span>        this.alpha = alpha;<a name="line.100"></a>
<span class="sourceLineNo">101</span>        this.l1Ratio = l1Ratio;<a name="line.101"></a>
<span class="sourceLineNo">102</span>        this.tolerance = tolerance;<a name="line.102"></a>
<span class="sourceLineNo">103</span>        this.maxIterations = maxIterations;<a name="line.103"></a>
<span class="sourceLineNo">104</span>        this.randomise = randomise;<a name="line.104"></a>
<span class="sourceLineNo">105</span>        this.seed = seed;<a name="line.105"></a>
<span class="sourceLineNo">106</span>        postConfig();<a name="line.106"></a>
<span class="sourceLineNo">107</span>    }<a name="line.107"></a>
<span class="sourceLineNo">108</span><a name="line.108"></a>
<span class="sourceLineNo">109</span>    @Override<a name="line.109"></a>
<span class="sourceLineNo">110</span>    public synchronized void postConfig() {<a name="line.110"></a>
<span class="sourceLineNo">111</span>        if ((l1Ratio &lt; DELTA) || (l1Ratio &gt; 1.0 + DELTA)) {<a name="line.111"></a>
<span class="sourceLineNo">112</span>            throw new PropertyException("l1Ratio","L1 Ratio must be between 0 and 1. Found value " + l1Ratio);<a name="line.112"></a>
<span class="sourceLineNo">113</span>        }<a name="line.113"></a>
<span class="sourceLineNo">114</span>        this.rng = new SplittableRandom(seed);<a name="line.114"></a>
<span class="sourceLineNo">115</span>    }<a name="line.115"></a>
<span class="sourceLineNo">116</span><a name="line.116"></a>
<span class="sourceLineNo">117</span>    @Override<a name="line.117"></a>
<span class="sourceLineNo">118</span>    public SparseModel&lt;Regressor&gt; train(Dataset&lt;Regressor&gt; examples, Map&lt;String, Provenance&gt; runProvenance) {<a name="line.118"></a>
<span class="sourceLineNo">119</span>        if (examples.getOutputInfo().getUnknownCount() &gt; 0) {<a name="line.119"></a>
<span class="sourceLineNo">120</span>            throw new IllegalArgumentException("The supplied Dataset contained unknown Outputs, and this Trainer is supervised.");<a name="line.120"></a>
<span class="sourceLineNo">121</span>        }<a name="line.121"></a>
<span class="sourceLineNo">122</span>        // Creates a new RNG, adds one to the invocation count, generates provenance.<a name="line.122"></a>
<span class="sourceLineNo">123</span>        TrainerProvenance trainerProvenance;<a name="line.123"></a>
<span class="sourceLineNo">124</span>        SplittableRandom localRNG;<a name="line.124"></a>
<span class="sourceLineNo">125</span>        synchronized(this) {<a name="line.125"></a>
<span class="sourceLineNo">126</span>            localRNG = rng.split();<a name="line.126"></a>
<span class="sourceLineNo">127</span>            trainerProvenance = getProvenance();<a name="line.127"></a>
<span class="sourceLineNo">128</span>            trainInvocationCounter++;<a name="line.128"></a>
<span class="sourceLineNo">129</span>        }<a name="line.129"></a>
<span class="sourceLineNo">130</span>        ImmutableFeatureMap featureIDMap = examples.getFeatureIDMap();<a name="line.130"></a>
<span class="sourceLineNo">131</span>        ImmutableOutputInfo&lt;Regressor&gt; outputInfo = examples.getOutputIDInfo();<a name="line.131"></a>
<span class="sourceLineNo">132</span>        int numFeatures = featureIDMap.size();<a name="line.132"></a>
<span class="sourceLineNo">133</span>        int numOutputs = outputInfo.size();<a name="line.133"></a>
<span class="sourceLineNo">134</span>        int numExamples = examples.size();<a name="line.134"></a>
<span class="sourceLineNo">135</span>        SparseVector[] columns = SparseVector.transpose(examples,featureIDMap);<a name="line.135"></a>
<span class="sourceLineNo">136</span>        String[] dimensionNames = new String[numOutputs];<a name="line.136"></a>
<span class="sourceLineNo">137</span>        DenseVector[] regressionTargets = new DenseVector[numOutputs];<a name="line.137"></a>
<span class="sourceLineNo">138</span>        for (int i = 0; i &lt; numOutputs; i++) {<a name="line.138"></a>
<span class="sourceLineNo">139</span>            dimensionNames[i] = outputInfo.getOutput(i).getNames()[0];<a name="line.139"></a>
<span class="sourceLineNo">140</span>            regressionTargets[i] = new DenseVector(numExamples);<a name="line.140"></a>
<span class="sourceLineNo">141</span>        }<a name="line.141"></a>
<span class="sourceLineNo">142</span>        int i = 0;<a name="line.142"></a>
<span class="sourceLineNo">143</span>        for (Example&lt;Regressor&gt; e : examples) {<a name="line.143"></a>
<span class="sourceLineNo">144</span>            int j = 0;<a name="line.144"></a>
<span class="sourceLineNo">145</span>            for (DimensionTuple d : e.getOutput()) {<a name="line.145"></a>
<span class="sourceLineNo">146</span>                regressionTargets[j].set(i, d.getValue());<a name="line.146"></a>
<span class="sourceLineNo">147</span>                j++;<a name="line.147"></a>
<span class="sourceLineNo">148</span>            }<a name="line.148"></a>
<span class="sourceLineNo">149</span>            i++;<a name="line.149"></a>
<span class="sourceLineNo">150</span>        }<a name="line.150"></a>
<span class="sourceLineNo">151</span>        double l1Penalty = alpha * l1Ratio * numExamples;<a name="line.151"></a>
<span class="sourceLineNo">152</span>        double l2Penalty = alpha * (1.0 - l1Ratio) * numExamples;<a name="line.152"></a>
<span class="sourceLineNo">153</span><a name="line.153"></a>
<span class="sourceLineNo">154</span>        double[] featureMeans = calculateMeans(columns);<a name="line.154"></a>
<span class="sourceLineNo">155</span>        double[] featureVariances = new double[columns.length];<a name="line.155"></a>
<span class="sourceLineNo">156</span>        Arrays.fill(featureVariances,1.0);<a name="line.156"></a>
<span class="sourceLineNo">157</span>        boolean center = false;<a name="line.157"></a>
<span class="sourceLineNo">158</span>        for (i = 0; i &lt; numFeatures; i++) {<a name="line.158"></a>
<span class="sourceLineNo">159</span>            if (Math.abs(featureMeans[i]) &gt; DELTA) {<a name="line.159"></a>
<span class="sourceLineNo">160</span>                center = true;<a name="line.160"></a>
<span class="sourceLineNo">161</span>                break;<a name="line.161"></a>
<span class="sourceLineNo">162</span>            }<a name="line.162"></a>
<span class="sourceLineNo">163</span>        }<a name="line.163"></a>
<span class="sourceLineNo">164</span>        double[] columnNorms = new double[numFeatures];<a name="line.164"></a>
<span class="sourceLineNo">165</span>        int[] featureIndices = new int[numFeatures];<a name="line.165"></a>
<span class="sourceLineNo">166</span><a name="line.166"></a>
<span class="sourceLineNo">167</span>        for (i = 0; i &lt; numFeatures; i++) {<a name="line.167"></a>
<span class="sourceLineNo">168</span>            featureIndices[i] = i;<a name="line.168"></a>
<span class="sourceLineNo">169</span>            double variance = 0.0;<a name="line.169"></a>
<span class="sourceLineNo">170</span>            for (VectorTuple v : columns[i]) {<a name="line.170"></a>
<span class="sourceLineNo">171</span>                variance += (v.value - featureMeans[i]) * (v.value - featureMeans[i]);<a name="line.171"></a>
<span class="sourceLineNo">172</span>            }<a name="line.172"></a>
<span class="sourceLineNo">173</span>            columnNorms[i] = variance + (numExamples - columns[i].numActiveElements()) * featureMeans[i] * featureMeans[i];<a name="line.173"></a>
<span class="sourceLineNo">174</span>        }<a name="line.174"></a>
<span class="sourceLineNo">175</span><a name="line.175"></a>
<span class="sourceLineNo">176</span>        ElasticNetState elState = new ElasticNetState(columns,featureIndices,featureMeans,columnNorms,l1Penalty,l2Penalty,center);<a name="line.176"></a>
<span class="sourceLineNo">177</span><a name="line.177"></a>
<span class="sourceLineNo">178</span>        SparseVector[] outputWeights = new SparseVector[numOutputs];<a name="line.178"></a>
<span class="sourceLineNo">179</span>        double[] outputMeans = new double[numOutputs];<a name="line.179"></a>
<span class="sourceLineNo">180</span>        for (int j = 0; j &lt; dimensionNames.length; j++) {<a name="line.180"></a>
<span class="sourceLineNo">181</span>            outputWeights[j] = trainSingleDimension(regressionTargets[j],elState,localRNG.split());<a name="line.181"></a>
<span class="sourceLineNo">182</span>            outputMeans[j] = regressionTargets[j].sum() / numExamples;<a name="line.182"></a>
<span class="sourceLineNo">183</span>        }<a name="line.183"></a>
<span class="sourceLineNo">184</span>        double[] outputVariances = new double[numOutputs];//calculateVariances(regressionTargets,outputMeans);<a name="line.184"></a>
<span class="sourceLineNo">185</span>        Arrays.fill(outputVariances,1.0);<a name="line.185"></a>
<span class="sourceLineNo">186</span><a name="line.186"></a>
<span class="sourceLineNo">187</span>        ModelProvenance provenance = new ModelProvenance(SparseLinearModel.class.getName(), OffsetDateTime.now(),examples.getProvenance(),trainerProvenance,runProvenance);<a name="line.187"></a>
<span class="sourceLineNo">188</span>        return new SparseLinearModel("elastic-net-model", dimensionNames, provenance, featureIDMap, outputInfo,<a name="line.188"></a>
<span class="sourceLineNo">189</span>                outputWeights, DenseVector.createDenseVector(featureMeans), DenseVector.createDenseVector(featureVariances),<a name="line.189"></a>
<span class="sourceLineNo">190</span>                outputMeans, outputVariances, false);<a name="line.190"></a>
<span class="sourceLineNo">191</span>    }<a name="line.191"></a>
<span class="sourceLineNo">192</span><a name="line.192"></a>
<span class="sourceLineNo">193</span>    private SparseVector trainSingleDimension(DenseVector regressionTargets, ElasticNetState state, SplittableRandom localRNG) {<a name="line.193"></a>
<span class="sourceLineNo">194</span>        int numFeatures = state.numFeatures;<a name="line.194"></a>
<span class="sourceLineNo">195</span>        int numExamples = state.numExamples;<a name="line.195"></a>
<span class="sourceLineNo">196</span>        DenseVector residuals = regressionTargets.copy();<a name="line.196"></a>
<span class="sourceLineNo">197</span>        DenseVector weights = new DenseVector(numFeatures);<a name="line.197"></a>
<span class="sourceLineNo">198</span>        double targetTwoNorm = regressionTargets.twoNorm();<a name="line.198"></a>
<span class="sourceLineNo">199</span>        double newTolerance = tolerance * targetTwoNorm * targetTwoNorm;<a name="line.199"></a>
<span class="sourceLineNo">200</span><a name="line.200"></a>
<span class="sourceLineNo">201</span>        double[] xTransposeR = new double[numFeatures];<a name="line.201"></a>
<span class="sourceLineNo">202</span>        double[] xTransposeAlpha = new double[numFeatures];<a name="line.202"></a>
<span class="sourceLineNo">203</span><a name="line.203"></a>
<span class="sourceLineNo">204</span>        for (int i = 0; i &lt; maxIterations; i++) {<a name="line.204"></a>
<span class="sourceLineNo">205</span>            double maxWeight = 0.0;<a name="line.205"></a>
<span class="sourceLineNo">206</span>            double maxUpdate = 0.0;<a name="line.206"></a>
<span class="sourceLineNo">207</span><a name="line.207"></a>
<span class="sourceLineNo">208</span>            // If randomly selecting the features, permute the indices<a name="line.208"></a>
<span class="sourceLineNo">209</span>            if (randomise) {<a name="line.209"></a>
<span class="sourceLineNo">210</span>                Util.randpermInPlace(state.featureIndices,localRNG);<a name="line.210"></a>
<span class="sourceLineNo">211</span>            }<a name="line.211"></a>
<span class="sourceLineNo">212</span><a name="line.212"></a>
<span class="sourceLineNo">213</span>            // Iterate through the features<a name="line.213"></a>
<span class="sourceLineNo">214</span>            for (int j = 0; j &lt; numFeatures; j++) {<a name="line.214"></a>
<span class="sourceLineNo">215</span>                int feature = state.featureIndices[j];<a name="line.215"></a>
<span class="sourceLineNo">216</span><a name="line.216"></a>
<span class="sourceLineNo">217</span>                if (Math.abs(state.columnNorms[feature]) &lt; DELTA) {<a name="line.217"></a>
<span class="sourceLineNo">218</span>                    continue;<a name="line.218"></a>
<span class="sourceLineNo">219</span>                }<a name="line.219"></a>
<span class="sourceLineNo">220</span><a name="line.220"></a>
<span class="sourceLineNo">221</span>                double oldWeight = weights.get(feature);<a name="line.221"></a>
<span class="sourceLineNo">222</span><a name="line.222"></a>
<span class="sourceLineNo">223</span>                // Update residual<a name="line.223"></a>
<span class="sourceLineNo">224</span>                if (oldWeight != 0.0) {<a name="line.224"></a>
<span class="sourceLineNo">225</span>                    for (VectorTuple v : state.columns[feature]) {<a name="line.225"></a>
<span class="sourceLineNo">226</span>                        residuals.set(v.index, residuals.get(v.index) + (v.value * oldWeight));<a name="line.226"></a>
<span class="sourceLineNo">227</span>                    }<a name="line.227"></a>
<span class="sourceLineNo">228</span>                    if (state.center) {<a name="line.228"></a>
<span class="sourceLineNo">229</span>                        for (int k = 0; k &lt; numExamples; k++) {<a name="line.229"></a>
<span class="sourceLineNo">230</span>                            residuals.set(k, residuals.get(k) - (state.featureMeans[feature] * oldWeight));<a name="line.230"></a>
<span class="sourceLineNo">231</span>                        }<a name="line.231"></a>
<span class="sourceLineNo">232</span>                    }<a name="line.232"></a>
<span class="sourceLineNo">233</span>                }<a name="line.233"></a>
<span class="sourceLineNo">234</span><a name="line.234"></a>
<span class="sourceLineNo">235</span>                // Update the weights in the required direction<a name="line.235"></a>
<span class="sourceLineNo">236</span>                double curDot = residuals.dot(state.columns[feature]);<a name="line.236"></a>
<span class="sourceLineNo">237</span>                if (state.center) {<a name="line.237"></a>
<span class="sourceLineNo">238</span>                    curDot -= residuals.sum() * state.featureMeans[feature];<a name="line.238"></a>
<span class="sourceLineNo">239</span>                }<a name="line.239"></a>
<span class="sourceLineNo">240</span>                double newWeight = Math.signum(curDot) * Math.max(Math.abs(curDot) - state.l1Penalty, 0) / (state.columnNorms[feature] + state.l2Penalty);<a name="line.240"></a>
<span class="sourceLineNo">241</span>                weights.set(feature,newWeight);<a name="line.241"></a>
<span class="sourceLineNo">242</span><a name="line.242"></a>
<span class="sourceLineNo">243</span>                // Update residual after step<a name="line.243"></a>
<span class="sourceLineNo">244</span>                if (newWeight != 0.0) {<a name="line.244"></a>
<span class="sourceLineNo">245</span>                    for (VectorTuple v : state.columns[feature]) {<a name="line.245"></a>
<span class="sourceLineNo">246</span>                        residuals.set(v.index, residuals.get(v.index) - (v.value * newWeight));<a name="line.246"></a>
<span class="sourceLineNo">247</span>                    }<a name="line.247"></a>
<span class="sourceLineNo">248</span>                    if (state.center) {<a name="line.248"></a>
<span class="sourceLineNo">249</span>                        for (int k = 0; k &lt; numExamples; k++) {<a name="line.249"></a>
<span class="sourceLineNo">250</span>                            residuals.set(k, residuals.get(k) + (state.featureMeans[feature] * newWeight));<a name="line.250"></a>
<span class="sourceLineNo">251</span>                        }<a name="line.251"></a>
<span class="sourceLineNo">252</span>                    }<a name="line.252"></a>
<span class="sourceLineNo">253</span>                }<a name="line.253"></a>
<span class="sourceLineNo">254</span><a name="line.254"></a>
<span class="sourceLineNo">255</span>                double curUpdate = Math.abs(newWeight - oldWeight);<a name="line.255"></a>
<span class="sourceLineNo">256</span><a name="line.256"></a>
<span class="sourceLineNo">257</span>                if (curUpdate &gt; maxUpdate) {<a name="line.257"></a>
<span class="sourceLineNo">258</span>                    maxUpdate = curUpdate;<a name="line.258"></a>
<span class="sourceLineNo">259</span>                }<a name="line.259"></a>
<span class="sourceLineNo">260</span><a name="line.260"></a>
<span class="sourceLineNo">261</span>                double absNewWeight = Math.abs(newWeight);<a name="line.261"></a>
<span class="sourceLineNo">262</span>                if (absNewWeight &gt; maxWeight) {<a name="line.262"></a>
<span class="sourceLineNo">263</span>                    maxWeight = absNewWeight;<a name="line.263"></a>
<span class="sourceLineNo">264</span>                }<a name="line.264"></a>
<span class="sourceLineNo">265</span>            }<a name="line.265"></a>
<span class="sourceLineNo">266</span><a name="line.266"></a>
<span class="sourceLineNo">267</span>            //logger.log(Level.INFO, "Iteration " + i + ", average residual = " + residuals.sum()/numExamples);<a name="line.267"></a>
<span class="sourceLineNo">268</span><a name="line.268"></a>
<span class="sourceLineNo">269</span>            // Check the termination condition<a name="line.269"></a>
<span class="sourceLineNo">270</span>            if ((maxWeight &lt; DELTA) || (maxUpdate / maxWeight &lt; tolerance) || (i == (maxIterations-1))) {<a name="line.270"></a>
<span class="sourceLineNo">271</span>                double residualSum = residuals.sum();<a name="line.271"></a>
<span class="sourceLineNo">272</span><a name="line.272"></a>
<span class="sourceLineNo">273</span>                double maxAbsXTA = 0.0;<a name="line.273"></a>
<span class="sourceLineNo">274</span>                for (int j = 0; j &lt; numFeatures; j++) {<a name="line.274"></a>
<span class="sourceLineNo">275</span>                    xTransposeR[j] = residuals.dot(state.columns[j]);<a name="line.275"></a>
<span class="sourceLineNo">276</span><a name="line.276"></a>
<span class="sourceLineNo">277</span>                    if (state.center) {<a name="line.277"></a>
<span class="sourceLineNo">278</span>                        xTransposeR[j] -= state.featureMeans[j] * residualSum;<a name="line.278"></a>
<span class="sourceLineNo">279</span>                    }<a name="line.279"></a>
<span class="sourceLineNo">280</span><a name="line.280"></a>
<span class="sourceLineNo">281</span>                    xTransposeAlpha[j] = xTransposeR[j] - state.l2Penalty * weights.get(j);<a name="line.281"></a>
<span class="sourceLineNo">282</span><a name="line.282"></a>
<span class="sourceLineNo">283</span>                    double curAbs = Math.abs(xTransposeAlpha[j]);<a name="line.283"></a>
<span class="sourceLineNo">284</span>                    if (curAbs &gt; maxAbsXTA) {<a name="line.284"></a>
<span class="sourceLineNo">285</span>                        maxAbsXTA = curAbs;<a name="line.285"></a>
<span class="sourceLineNo">286</span>                    }<a name="line.286"></a>
<span class="sourceLineNo">287</span>                }<a name="line.287"></a>
<span class="sourceLineNo">288</span><a name="line.288"></a>
<span class="sourceLineNo">289</span>                double residualTwoNorm = residuals.twoNorm();<a name="line.289"></a>
<span class="sourceLineNo">290</span>                residualTwoNorm *= residualTwoNorm;<a name="line.290"></a>
<span class="sourceLineNo">291</span><a name="line.291"></a>
<span class="sourceLineNo">292</span>                double weightsTwoNorm = weights.twoNorm();<a name="line.292"></a>
<span class="sourceLineNo">293</span>                weightsTwoNorm *= weightsTwoNorm;<a name="line.293"></a>
<span class="sourceLineNo">294</span><a name="line.294"></a>
<span class="sourceLineNo">295</span>                double weightsOneNorm = weights.oneNorm();<a name="line.295"></a>
<span class="sourceLineNo">296</span><a name="line.296"></a>
<span class="sourceLineNo">297</span>                double scalingFactor, dualityGap;<a name="line.297"></a>
<span class="sourceLineNo">298</span>                if (maxAbsXTA &gt; state.l1Penalty) {<a name="line.298"></a>
<span class="sourceLineNo">299</span>                    scalingFactor = state.l1Penalty / maxAbsXTA;<a name="line.299"></a>
<span class="sourceLineNo">300</span>                    double alphaNorm = residualTwoNorm * scalingFactor * scalingFactor;<a name="line.300"></a>
<span class="sourceLineNo">301</span>                    dualityGap = 0.5 * (residualTwoNorm + alphaNorm);<a name="line.301"></a>
<span class="sourceLineNo">302</span>                } else {<a name="line.302"></a>
<span class="sourceLineNo">303</span>                    scalingFactor = 1.0;<a name="line.303"></a>
<span class="sourceLineNo">304</span>                    dualityGap = residualTwoNorm;<a name="line.304"></a>
<span class="sourceLineNo">305</span>                }<a name="line.305"></a>
<span class="sourceLineNo">306</span><a name="line.306"></a>
<span class="sourceLineNo">307</span>                dualityGap += state.l1Penalty * weightsOneNorm - scalingFactor * residuals.dot(regressionTargets);<a name="line.307"></a>
<span class="sourceLineNo">308</span>                dualityGap += 0.5 * state.l2Penalty * (1 + (scalingFactor * scalingFactor)) * weightsTwoNorm;<a name="line.308"></a>
<span class="sourceLineNo">309</span><a name="line.309"></a>
<span class="sourceLineNo">310</span>                if (dualityGap &lt; newTolerance) {<a name="line.310"></a>
<span class="sourceLineNo">311</span>                    // All done, stop iterating.<a name="line.311"></a>
<span class="sourceLineNo">312</span>                    logger.log(Level.INFO,"Iteration: " + i + ", duality gap = " + dualityGap + ", tolerance = " + newTolerance);<a name="line.312"></a>
<span class="sourceLineNo">313</span>                    break;<a name="line.313"></a>
<span class="sourceLineNo">314</span>                }<a name="line.314"></a>
<span class="sourceLineNo">315</span>            }<a name="line.315"></a>
<span class="sourceLineNo">316</span>        }<a name="line.316"></a>
<span class="sourceLineNo">317</span><a name="line.317"></a>
<span class="sourceLineNo">318</span><a name="line.318"></a>
<span class="sourceLineNo">319</span>        return weights.sparsify();<a name="line.319"></a>
<span class="sourceLineNo">320</span>    }<a name="line.320"></a>
<span class="sourceLineNo">321</span><a name="line.321"></a>
<span class="sourceLineNo">322</span>    @Override<a name="line.322"></a>
<span class="sourceLineNo">323</span>    public int getInvocationCount() {<a name="line.323"></a>
<span class="sourceLineNo">324</span>        return trainInvocationCounter;<a name="line.324"></a>
<span class="sourceLineNo">325</span>    }<a name="line.325"></a>
<span class="sourceLineNo">326</span><a name="line.326"></a>
<span class="sourceLineNo">327</span>    @Override<a name="line.327"></a>
<span class="sourceLineNo">328</span>    public String toString() {<a name="line.328"></a>
<span class="sourceLineNo">329</span>        return "ElasticNetCDTrainer(alpha="+alpha+",l1Ratio="+l1Ratio+"" +<a name="line.329"></a>
<span class="sourceLineNo">330</span>                ",tolerance="+tolerance+",maxIterations="+maxIterations +<a name="line.330"></a>
<span class="sourceLineNo">331</span>                ",randomise="+randomise+",seed="+seed+")";<a name="line.331"></a>
<span class="sourceLineNo">332</span>    }<a name="line.332"></a>
<span class="sourceLineNo">333</span><a name="line.333"></a>
<span class="sourceLineNo">334</span>    private static double[] calculateMeans(SGDVector[] columns) {<a name="line.334"></a>
<span class="sourceLineNo">335</span>        double[] means = new double[columns.length];<a name="line.335"></a>
<span class="sourceLineNo">336</span><a name="line.336"></a>
<span class="sourceLineNo">337</span>        for (int i = 0; i &lt; means.length; i++) {<a name="line.337"></a>
<span class="sourceLineNo">338</span>            means[i] = columns[i].sum() / columns[i].size();<a name="line.338"></a>
<span class="sourceLineNo">339</span>        }<a name="line.339"></a>
<span class="sourceLineNo">340</span><a name="line.340"></a>
<span class="sourceLineNo">341</span>        return means;<a name="line.341"></a>
<span class="sourceLineNo">342</span>    }<a name="line.342"></a>
<span class="sourceLineNo">343</span><a name="line.343"></a>
<span class="sourceLineNo">344</span>    private static double[] calculateVariances(SGDVector[] columns, double[] means) {<a name="line.344"></a>
<span class="sourceLineNo">345</span>        double[] variances = new double[columns.length];<a name="line.345"></a>
<span class="sourceLineNo">346</span><a name="line.346"></a>
<span class="sourceLineNo">347</span>        for (int i = 0; i &lt; variances.length; i++) {<a name="line.347"></a>
<span class="sourceLineNo">348</span>            variances[i] = columns[i].variance(means[i]);<a name="line.348"></a>
<span class="sourceLineNo">349</span>        }<a name="line.349"></a>
<span class="sourceLineNo">350</span><a name="line.350"></a>
<span class="sourceLineNo">351</span>        return variances;<a name="line.351"></a>
<span class="sourceLineNo">352</span>    }<a name="line.352"></a>
<span class="sourceLineNo">353</span><a name="line.353"></a>
<span class="sourceLineNo">354</span>    @Override<a name="line.354"></a>
<span class="sourceLineNo">355</span>    public TrainerProvenance getProvenance() {<a name="line.355"></a>
<span class="sourceLineNo">356</span>        return new TrainerProvenanceImpl(this);<a name="line.356"></a>
<span class="sourceLineNo">357</span>    }<a name="line.357"></a>
<span class="sourceLineNo">358</span><a name="line.358"></a>
<span class="sourceLineNo">359</span>    /**<a name="line.359"></a>
<span class="sourceLineNo">360</span>     * Carrier type for the immutable elastic net state.<a name="line.360"></a>
<span class="sourceLineNo">361</span>     */<a name="line.361"></a>
<span class="sourceLineNo">362</span>    private static class ElasticNetState {<a name="line.362"></a>
<span class="sourceLineNo">363</span>        final SparseVector[] columns;<a name="line.363"></a>
<span class="sourceLineNo">364</span>        final int numFeatures;<a name="line.364"></a>
<span class="sourceLineNo">365</span>        final int numExamples;<a name="line.365"></a>
<span class="sourceLineNo">366</span>        final int[] featureIndices;<a name="line.366"></a>
<span class="sourceLineNo">367</span>        final double[] featureMeans;<a name="line.367"></a>
<span class="sourceLineNo">368</span>        final double[] columnNorms;<a name="line.368"></a>
<span class="sourceLineNo">369</span>        final double l1Penalty;<a name="line.369"></a>
<span class="sourceLineNo">370</span>        final double l2Penalty;<a name="line.370"></a>
<span class="sourceLineNo">371</span>        final boolean center;<a name="line.371"></a>
<span class="sourceLineNo">372</span><a name="line.372"></a>
<span class="sourceLineNo">373</span>        public ElasticNetState(SparseVector[] columns, int[] featureIndices, double[] featureMeans, double[] columnNorms, double l1Penalty, double l2Penalty, boolean center) {<a name="line.373"></a>
<span class="sourceLineNo">374</span>            this.columns = columns;<a name="line.374"></a>
<span class="sourceLineNo">375</span>            this.numFeatures = columns.length;<a name="line.375"></a>
<span class="sourceLineNo">376</span>            this.numExamples = columns[0].size();<a name="line.376"></a>
<span class="sourceLineNo">377</span>            this.featureIndices = featureIndices;<a name="line.377"></a>
<span class="sourceLineNo">378</span>            this.featureMeans = featureMeans;<a name="line.378"></a>
<span class="sourceLineNo">379</span>            this.columnNorms = columnNorms;<a name="line.379"></a>
<span class="sourceLineNo">380</span>            this.l1Penalty = l1Penalty;<a name="line.380"></a>
<span class="sourceLineNo">381</span>            this.l2Penalty = l2Penalty;<a name="line.381"></a>
<span class="sourceLineNo">382</span>            this.center = center;<a name="line.382"></a>
<span class="sourceLineNo">383</span>        }<a name="line.383"></a>
<span class="sourceLineNo">384</span>    }<a name="line.384"></a>
<span class="sourceLineNo">385</span>}<a name="line.385"></a>




























































</pre>
</div>
</body>
</html>
